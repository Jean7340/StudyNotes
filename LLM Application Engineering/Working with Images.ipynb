{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a242fbc-e650-4ddd-bf26-e2a8184c1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_api_key\")\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23468e0b-d84d-4523-a9c6-4657ba4c2c90",
   "metadata": {},
   "source": [
    "DALL-E-3 is the newest OpenAI art generator.  \n",
    "\n",
    "Either DALL-E-3 or DALL-E-2 can be used to generate new images.  Currently, only DALL-E-2 supports image editing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0b2b36-f876-400e-9691-40d12c1e484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_prompt(prompt_input, model_input = \"dall-e-3\", size_input = \"1024x1024\"):\n",
    "    \n",
    "    response = client.images.generate(\n",
    "        model = model_input,\n",
    "        prompt = prompt_input,\n",
    "        size = size_input,\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    image_url = response.data[0].url\n",
    "    \n",
    "    return image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e560e038-7c76-4472-8426-5c75760b4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Draw a white dog with a silly expression and a brown patch over one ear.\n",
    "\"\"\"\n",
    "\n",
    "image = get_image_from_prompt(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856d70ee-2347-428e-b63a-0e348c7f5728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-4ZePUkYJmQNuydDbo1KDIHag/user-4057MPs6jnbR83KPARDDssho/img-tQ00lROYA1FQPypB0RiFbfOf.png?st=2025-04-16T13%3A08%3A30Z&se=2025-04-16T15%3A08%3A30Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=cc612491-d948-4d2e-9821-2683df3719f5&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-16T05%3A03%3A37Z&ske=2025-04-17T05%3A03%3A37Z&sks=b&skv=2024-08-04&sig=y%2BAxXuwaghwUV2SFszaETXkKTPmiL/pJElrnmRZRJD4%3D'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b1084d-5fd6-40d2-ae39-427452c6e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(prompt, model_input=\"gpt-4o-mini\", temperature_input = .5) :\n",
    "    messages_from_prompt = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model = model_input,\n",
    "        messages = messages_from_prompt,\n",
    "        temperature = temperature_input\n",
    "    )\n",
    "    response = response.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c32fda8d-4797-4029-9b81-ef9c2316f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('home_goods_reviews.csv')\n",
    "products = df['product']\n",
    "\n",
    "prompt_companyAdjectives_suggestion = f'List 3 adjectives that would describe the target customer of a company that makes {products}?'\n",
    "companyAdjectives = get_output(prompt_companyAdjectives_suggestion, temperature_input = 1)\n",
    "\n",
    "prompt_ad_suggestion = f\"\"\"\n",
    "Draw a banner image for a company described as {companyAdjectives}.\n",
    "Include one or more of the items in the list {products} in the logo design.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "image = get_image_from_prompt(prompt_ad_suggestion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe807c0-8e5a-4151-96dd-6bb759880677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three adjectives that could describe the target customer for a company that makes the listed home and lifestyle products:\n",
      "\n",
      "1. **Discerning** - This customer values quality and is likely to seek out well-made products that enhance their home experience.\n",
      "\n",
      "2. **Health-conscious** - Many of the items, such as non-stick cookware and air purifiers, appeal to individuals who prioritize health and wellness in their living spaces.\n",
      "\n",
      "3. **Style-oriented** - With products like decorative wall mirrors and woven laundry hampers, this customer appreciates aesthetics and seeks to create a visually appealing and functional environment.\n"
     ]
    }
   ],
   "source": [
    "print(companyAdjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0f2ec5-2df5-41ee-8f14-31a85ae55ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-4ZePUkYJmQNuydDbo1KDIHag/user-4057MPs6jnbR83KPARDDssho/img-3XGcsKqhycVnI1TmjvWdNbiv.png?st=2025-04-16T13%3A08%3A59Z&se=2025-04-16T15%3A08%3A59Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=cc612491-d948-4d2e-9821-2683df3719f5&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-16T05%3A52%3A32Z&ske=2025-04-17T05%3A52%3A32Z&sks=b&skv=2024-08-04&sig=0jPvMBLcSDud7HZZJaTCt9buRGtlWCZRERuve2rqmMY%3D'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31254ea1-df23-4a48-be40-5ef65ccbbebb",
   "metadata": {},
   "source": [
    "**Generating Content/Image Descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b89ec36-2f0e-423c-8770-48e70e112e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_from_messages(messages_input, model_input = \"gpt-4o-mini\", temperature_input = 1):\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = model_input,\n",
    "        messages = messages_input,\n",
    "        temperature = temperature_input,\n",
    "    )\n",
    "\n",
    "    response = response.choices[0].message.content\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5ebaf31-9256-40f5-afb7-aa80bf874067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_system_message(system_message):\n",
    "    context = [ {'role':'system', 'content': system_message} ]\n",
    "    return context\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a real estate assistant.  Take the images supplied of the interior and exterior of the home,\n",
    "and write a detailed property description for a sale listing.  Be sure to mention specific features that can be seen in the\n",
    "images of the important rooms, like the kitchen, family room, master bedroom and backyard.\n",
    "\"\"\"\n",
    "\n",
    "context = initialize_system_message(system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446cd5c-438a-42d0-abd4-4e6a7630d66b",
   "metadata": {},
   "source": [
    "base64.b64encode(...) encodes an image file (binary data) into Base64 format, which converts it to a textual representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7311ef13-e76c-41de-9dd1-4c7c1a917edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de4b09df-7148-4706-ab46-277681a12c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_single_image(image):\n",
    "    with open(image, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    return encoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b875892-e0a2-4e7a-b747-79e3c8bbae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(image_folder):\n",
    "    encoded_images = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        f = os.path.join(image_folder, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            with open(f, \"rb\") as image_file:\n",
    "                encoded_images.append(base64.b64encode(image_file.read()).decode('utf-8'))\n",
    "    return encoded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "356d35ff-5163-440e-ada1-2fe43d75e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your image folder\n",
    "image_folder = \"./images\"\n",
    "\n",
    "images = encode_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3cffc51-be59-4d47-82e6-c7c606e86496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_images(context, images):\n",
    "    for image in images:\n",
    "        context.append({\"role\": \"user\", \"content\": [{\"type\": \"image_url\",\"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"}}]})\n",
    "    response = get_output_from_messages(context, temperature_input = 1)\n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    return context, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a82b941-c7f3-4cec-907d-c409cfab48c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Property Description\n",
      "\n",
      "Welcome to this charming and spacious home located at **285 [Street Name]**, offering a perfect blend of modern living and outdoor tranquility. This beautifully updated residence features four comfortable bedrooms and two bathrooms, ideal for families.\n",
      "\n",
      "#### **Exterior Features**\n",
      "As you approach, you'll be greeted by a well-kept lawn framed by trees, providing a serene environment. The classic façade is complemented by black shutters and a welcoming front porch—perfect for enjoying your morning coffee or evening sunsets. A spacious driveway leads to a two-car garage, providing ample parking.\n",
      "\n",
      "#### **Interior Features**\n",
      "\n",
      "**Living Areas:**\n",
      "Step inside to discover a bright and airy layout, with a cozy living room that flows seamlessly into the dining area. Large windows bathe the space in natural light while offering lovely views of the expansive backyard.\n",
      "\n",
      "**Kitchen:**\n",
      "The heart of the home, the kitchen, boasts modern cabinetry and granite countertops, paired with stainless steel appliances that cater to your culinary needs. Ample storage and counter space make this kitchen both functional and stylish.\n",
      "\n",
      "**Dining Room:**\n",
      "Adjacent to the kitchen, the dining room features a chic table setup with comfortable seating, perfect for family gatherings or entertaining guests. The modern light fixture adds a touch of elegance to your dining experience.\n",
      "\n",
      "**Bedrooms:**\n",
      "The master bedroom is a true retreat, showcasing a feature wall of stylish brick and bright, oversized windows. It’s spacious enough for a king-sized bed and comes complete with abundant closet space. Additional bedrooms are equally inviting, perfect for family members or guests.\n",
      "\n",
      "**Sunroom:**\n",
      "A delightful sunroom awaits, offering a space to unwind while overlooking the lush backyard. This versatile area makes for a great reading spot or playroom, with large windows that invite the outdoors inside.\n",
      "\n",
      "**Backyard:**\n",
      "The backyard is a true oasis, featuring a generous green space with well-maintained landscaping and mature trees. It’s fenced for privacy, making it ideal for pets, children, or hosting summer barbecues.\n",
      "\n",
      "#### **Location:**\n",
      "Situated in a welcoming neighborhood, this home is conveniently located near local schools, parks, and shopping centers, ensuring all your needs are just a short drive away.\n",
      "\n",
      "Don’t miss the opportunity to make this lovely home yours. Schedule a viewing today!\n"
     ]
    }
   ],
   "source": [
    "context, response = add_images(context, images)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a0ec5a-be5c-4263-997a-0899ecaf9ae2",
   "metadata": {},
   "source": [
    "**Generating Data from Images**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8cc0bfa-c5a0-4ad9-bdac-2b42abcd4f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4ZePUkYJmQNuydDbo1KDIHag on tokens per min (TPM): Limit 200000, Used 200000, Requested 794. Please try again in 238ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m      4\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mList all the brands found in this picture.\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124mFormat the output as a comma separated value (csv) list.\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      9\u001b[0m message \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[0;32m     10\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/jpeg;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoded_grocery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}}]}  \n\u001b[0;32m     11\u001b[0m           ]\n\u001b[1;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m get_output_from_messages(message, temperature_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mget_output_from_messages\u001b[1;34m(messages_input, model_input, temperature_input)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_output_from_messages\u001b[39m(messages_input, model_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      4\u001b[0m         model \u001b[38;5;241m=\u001b[39m model_input,\n\u001b[0;32m      5\u001b[0m         messages \u001b[38;5;241m=\u001b[39m messages_input,\n\u001b[0;32m      6\u001b[0m         temperature \u001b[38;5;241m=\u001b[39m temperature_input,\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      9\u001b[0m     response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:863\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    860\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    862\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    866\u001b[0m             {\n\u001b[0;32m    867\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    868\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    869\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    870\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    871\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    872\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    873\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    874\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    875\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    876\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    877\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    878\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    879\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    880\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    881\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    882\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    883\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    884\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    885\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    886\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    887\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    888\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    889\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    890\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    891\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    892\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    893\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    894\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    895\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    896\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    897\u001b[0m             },\n\u001b[0;32m    898\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    899\u001b[0m         ),\n\u001b[0;32m    900\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    901\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    902\u001b[0m         ),\n\u001b[0;32m    903\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    904\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    905\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    906\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1282\u001b[0m     )\n\u001b[1;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    961\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    962\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    963\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    964\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    965\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1049\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1048\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1050\u001b[0m         input_options,\n\u001b[0;32m   1051\u001b[0m         cast_to,\n\u001b[0;32m   1052\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1053\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1054\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1055\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1098\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1099\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1100\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1101\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1102\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1103\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1104\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1049\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1048\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1050\u001b[0m         input_options,\n\u001b[0;32m   1051\u001b[0m         cast_to,\n\u001b[0;32m   1052\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1053\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1054\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1055\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1098\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1099\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1100\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1101\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1102\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1103\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1104\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1073\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4ZePUkYJmQNuydDbo1KDIHag on tokens per min (TPM): Limit 200000, Used 200000, Requested 794. Please try again in 238ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "grocery_image = (\"grocery.jpg\")\n",
    "encoded_grocery = encode_single_image(grocery_image)\n",
    "\n",
    "prompt = f'''\n",
    "List all the brands found in this picture.\n",
    "Format the output as a comma separated value (csv) list.\n",
    "'''\n",
    "\n",
    "message = [{\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"image_url\",\"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_grocery}\"}}]}  \n",
    "          ]\n",
    "\n",
    "response = get_output_from_messages(message, temperature_input = 1)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
